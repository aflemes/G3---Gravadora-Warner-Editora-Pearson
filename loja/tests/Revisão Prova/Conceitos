Sistemas distribuidos e Programação Paralela - Conceitos
Programação Paralela -
Consiste em executar simultaneamente varias partes de uma mesma aplicação, tornou-se possível graças ao desenvolvimento dos SO's com funções multi-thread.
Elas podem ser executadas em um mesmo processador, em uma maquina multiprocessada, ou em um cluster (varias maquina ligadas);

Sistemas distrivuidos - 
Consiste em executar aplicações cooperantes em máquinas diferentes, tornou-se possível graças ao avanço das redes de computadores.
"É uma coleção de computadores independentes entre si que se apresenta ao usuário como um sistema único e coerente"
"Coleção de computadores autônomos interligados através de uma rede de computadores e equipados com software que permita o compartilhamento dos recursos do sistema: hardware, software e dados"

Taxonomia de Flynn-
É uma classificação a cerca das arquiteturas de computadores porposta por Flynn segue elas:
SISD - Single Instruction Single Data
	 - Exemplo:  Processador com um core apenas.
SIMD - Single Instruction Multiple Data
	 - Exemplo: Muito utilizada em processamento de vetores ou matrizes e também nas GPUS (placas gráficas)
MISD - Multiple Instruction Single Data
	 - Exemplo: Não existe, porém, a quem diga que arquiteutras pipelines representam isso.
MIMD - Multiple Instruction Multiple Data
 	 - Exemplo: Maquinas mulitprocessadas e clusters

Multiprocessadores -
 Todos os processadores se comunicam atraves de uma memoria compartilhada.
 - Vantagens - Menor custo na comunicação 
 - Desvantagens - Maior custo de hardware, limite físico na quantidade  de processadores.

Multicomputadores -
Cada processaodr possui a sua própria memoria, se comunicam através de troca de mensagens (rede);
- Vantagens - Baixo Custo de Hardware, Acesso a memória local sem concorrência.
- Desvantagens - Responsabilidade do programador em sincronizar a comunicação.


Sockets -
Basicamente é um meio de comunicação fim to fim para comunicar dois aplicativos pela rede.
Ele é definido como: um IP e uma PORTA.
Implementado atraves de duas primitivas:
Send - NÃO bloqueante.
Receive - Bloqueante.
A transferencia de dados pode ser feita por:
UDP -
Não é orientada a conexão, não garante a entrega do pacote, pode entregar pacotes duplicados e não garante a entrega.
- Vantagens: Protocolo mais rápido que o TCP
- Desvantagens: TODAS.
TCP-
É orientada a conexão, é mais confiável pois ela garante a entrega do pacote (quando entregue o pacote ele envio um retorno confirmando a entrega), garante a ordem de entrega.
- Vantagens: Garantia de entrega, confiabilidade.
- Desvantagens - É mais lenta que o UDP;

Onde utilizar?
TCP - Transferencia de arquivos via FTP, envio e recebimento de emails.
UDP - Streaming de audio e video, servicos que admintem certa perda de pacotes.

FLUXO
- UDP
Server -> socket -> bind -> recvfrom -> sendto  -> close
Client -> socket ->      -> sendto	 -> recvfrom-> close

- TCP
Server -> socket -> bind	-> listen -> accept  -> recv -> send -> close
Client -> socket ->                   -> connect -> send -> recv -> close

RPC -
Procedural - Remote Procedure Call
Características
Toda comunicação entre processos é similar a chamada de procedimentos convencional
Fluxograma->
Cliente  -> Rotinas do cliente -> Stub do Cliente -> Camada de Rede ->
Servidor -> 										 Camada de Rede -> Stub do Servidor -> Rotina do Servidor.

Stubs - (XDR)
Def. Implementações "falsas" dos procedimentos.
Client   - Converte para o stub -> envio de mensagem ao servidor -> bloqueia aguardando o receive
Servidor - Converte de stub para local -> chama a rotina no servidor -> recebe o resultado e converte para stub -> envia ao cliente 

O RPC pode ser identificado por um part (program, version, procedure).

Program - corresponde a um inteiro e identifica o programa remoto (HEXADECIMAL);
Version - Controle das versões para os programas remotos, permite ao computador possuir diferentes versoes do mesmo programa.
Procedure - Identificador do procedimento remoto. (numero inteiro sequencial).

Um programa RPC não utiliza uma porta conhecida, ou seja, na incializacao, o RPC solicita ao SO uma porta não conhecida (PORT Mapper);
Caracteristicas - Ao iniciar ele recebe do SO a porta.
				- Apos o servidor registra o port mapper enviando o programa rpc e a versão.

Aqui as passagens são feitas por copias, uma passagem por referencia nao tem sentido.
 
O RPC possui uma linguagem propria denominada IDL (Interface Definition Language) semelahante ao C.
O Arquivo principal, onde ira conter o oprograma, versao e procedure é um arquivo com extensao .x, utilizando o compilador rpcgen, é criado os arquivos referente ao client servidor e os stubs, etc.


RMI -
Permite a execucação de chamadas no estilo RPC porem, desenvolvidas em JAVA 
Possibilita a invocação de um metodo remoto como se fosse local
Tambem se baseia na utilização de stubs -
O Cliente chama o metodo remoto usando um stub-
O Stub chama o Skeleton do servidor passando os parametros
O Skeleton recebe os parametros e chamada o metodo do servidor
O Servidor retorna o resultado o Skeleton que por sua vez chama o stub do client.
O Stub do client retorna o resultado como se tivesse sido gerado localmente.

RMI (trafega em binario (mais rapido que webservice))
Um objeto remoto é obtido atraves do servidor de nomes RMI Registry.
Como implementar um RMI.
Define a interface -> Implementar os objetos remotos -> Implementar um servidor para os objetos -> Compilar os objetos remotos -> Gerar os stubs e skeletons via rmic -> Implementar um Client -> Iniciar o RMI Registy -> Exercutar o servidor e o cliente.


OpenMP -
É uma biblioteca para desenvolvimento de aplicações paralelas que fazem uso de memoria compartilhada (ou seja, no mesmo computador)
- Não possui mecanismo para troca de mensagens
- O Modelo de execuação segue o paradigma de fork-join.
- Diretiva #pragma omp parallel (-fopenmp)
- Em OpenMP as variaveis são compartilhadas, ou seja, todas as threads estão alterando o valor da variavel, para contornar isso, é utilizado a palavra reservada "private" para designar as variaveis que serão privadas na execucação.
Em OpenMP o paralelismo pode ser obetido em dois diferentes niveis, (Paralelismo de laço (loop (for)) e criação de região paralelas )
Loop Level -
Só é preciso definir o inicio e o fim do paralelismo, cada thread vai esperar até que todas as outras tenham executado a sua parte do codigo.

Parallel region -
Como o parallel region nao possui laco de repetição, o tratamento das seçõe criticas fica a cargo do programador, a sincroização das threads sera feita pela diretiva #omp parallel barrier, ou seja, sem essa diretiva, as threads ficaram desincronizadas, desta forma, umas threads vao ser finalizadas antes das outras, etc.
Com a diretiva #omp parallel critical, a variavel compartilhada que estiver dentro desse bloco estará protegida, ou seja, o valor só será alterado por uma outra thread caso a thread original libere a variavel, desta forma, NUNCA havará duas threads alterando o valor da variavel simultanemanet.